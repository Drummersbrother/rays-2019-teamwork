{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow.keras.layers as klayer\n",
    "\n",
    "#from keras.layers import Input, Dense, Dropout, Activation, concatenate, BatchNormalization\n",
    "from keras.models import Model\n",
    "#from keras.layers import Conv2D, GlobalAveragePooling2D, AveragePooling2D, MaxPooling2D, UpSampling2D\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras_contrib.losses.jaccard import jaccard_distance as jaccard\n",
    "from keras import metrics\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "import keras.backend as K\n",
    "\n",
    "from tensorboard.plugins.beholder import Beholder\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load config\"\"\"\n",
    "with open(\"/home/hugo_dev/Desktop/Git-Repos/rays-2019/rays-2019-teamwork/kaggle_project/config.json\", mode=\"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "data_dir = config[\"data_dir\"]\n",
    "mask_csv_filename = config[\"mask_csv_filename\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Define losses and metrics\"\"\"\n",
    "def create_weighted_binary_crossentropy(zero_weight, one_weight):\n",
    "\n",
    "    def weighted_binary_crossentropy(y_true, y_pred):\n",
    "\n",
    "        # Original binary crossentropy (see losses.py):\n",
    "        # K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "        # Calculate the binary crossentropy\n",
    "        b_ce = K.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "        # Apply the weights\n",
    "        weight_vector = y_true * one_weight + (1. - y_true) * zero_weight\n",
    "        weighted_b_ce = weight_vector * b_ce\n",
    "\n",
    "        # Return the mean error\n",
    "        return K.mean(weighted_b_ce)\n",
    "\n",
    "    return weighted_binary_crossentropy\n",
    "\n",
    "\n",
    "class BeholderCallback(Callback):\n",
    "    def __init__(self, log_dir):\n",
    "        self.log_dir = log_dir\n",
    "        self.beholder = Beholder(log_dir)\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        pass\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None, *args, **kwargs):\n",
    "        K = keras.backend.backend\n",
    "        sess = keras.backend.get_session()\n",
    "        self.beholder.update(session=sess)\n",
    "\n",
    "\n",
    "def mod_jaccard(y_true, y_pred, smooth=1):\n",
    "    K = keras.backend\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (jac) * smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Define neural network models\"\"\"\n",
    "\n",
    "def unet(learning_rate, pretrained_weights=None, input_size=(256, 256, 1), down_sampling=4, give_intermediate=False, main_activation=\"relu\", k_initializer=\"he_normal\", zero_weight = 0.5):\n",
    "    \"\"\"Directly taken from https://github.com/zhixuhao/unet. Modified to fit into memory\"\"\"\n",
    "    inputs = klayer.Input(input_size)\n",
    "    conv1 = klayer.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = klayer.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = klayer.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = klayer.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = klayer.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = klayer.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = klayer.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = klayer.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = klayer.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = klayer.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = klayer.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = klayer.Dropout(0.5)(conv4)\n",
    "    pool4 = klayer.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = klayer.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = klayer.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = klayer.Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = klayer.Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(klayer.UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = klayer.concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = klayer.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = klayer.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = klayer.Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(klayer.UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = klayer.concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = klayer.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = klayer.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = klayer.Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(klayer.UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = klayer.concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = klayer.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = klayer.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = klayer.Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(klayer.UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = klayer.concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = klayer.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = klayer.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = klayer.Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = klayer.Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    out_layer = conv10\n",
    "\n",
    "    layers = [conv1, conv2, conv3, conv4, conv5, conv6, conv7, conv8, conv9, conv10, out_layer]\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=layers if give_intermediate else out_layer)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate), loss=keras.losses.MSE, metrics=[metrics.binary_accuracy, mod_jaccard])\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    if pretrained_weights:\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def unet_orig(learning_rate, pretrained_weights=None, input_size=(1024, 1024, 1), down_sampling=4, give_intermediate=False, main_activation=\"relu\", k_initializer=\"he_normal\", zero_weight = 0.5):\n",
    "    \"\"\"Almost directly taken from https://github.com/zhixuhao/unet. Modified to fit into memory\"\"\"\n",
    "    inputs = klayer.Input(input_size)\n",
    "    # Rescale to not take too much memory\n",
    "    scaled_inputs = klayer.MaxPooling2D(pool_size=(down_sampling, down_sampling))(inputs)\n",
    "    conv1 = klayer.Conv2D(64, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(scaled_inputs)\n",
    "    conv1 = klayer.Conv2D(64, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(conv1)\n",
    "    pool1 = klayer.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = klayer.Conv2D(128, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(pool1)\n",
    "    conv2 = klayer.Conv2D(128, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(conv2)\n",
    "    pool2 = klayer.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = klayer.Conv2D(256, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(pool2)\n",
    "    conv3 = klayer.Conv2D(256, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(conv3)\n",
    "    pool3 = klayer.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = klayer.Conv2D(512, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(pool3)\n",
    "    conv4 = klayer.Conv2D(512, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(conv4)\n",
    "    drop4 = klayer.Dropout(0.5)(conv4)\n",
    "    pool4 = klayer.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = klayer.Conv2D(1024, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(pool4)\n",
    "    conv5 = klayer.Conv2D(1024, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(conv5)\n",
    "    drop5 = klayer.Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = klayer.Conv2D(512, 2, activation=main_activation, padding='same', kernel_initializer=k_initializer)(\n",
    "        klayer.UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = klayer.concatenate([drop4, up6], axis=3)\n",
    "    conv6 = klayer.Conv2D(512, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(merge6)\n",
    "    conv6 = klayer.Conv2D(512, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(conv6)\n",
    "\n",
    "    up7 = klayer.Conv2D(256, 2, activation=main_activation, padding='same', kernel_initializer=k_initializer)(\n",
    "        klayer.UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = klayer.concatenate([conv3, up7], axis=3)\n",
    "    conv7 = klayer.Conv2D(256, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(merge7)\n",
    "    conv7 = klayer.Conv2D(256, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(conv7)\n",
    "\n",
    "    up8 = klayer.Conv2D(128, 2, activation=main_activation, padding='same', kernel_initializer=k_initializer)(\n",
    "        klayer.UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = klayer.concatenate([conv2, up8], axis=3)\n",
    "    conv8 = klayer.Conv2D(128, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(merge8)\n",
    "    conv8 = klayer.Conv2D(128, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(conv8)\n",
    "\n",
    "    up9 = klayer.Conv2D(64, 2, activation=main_activation, padding='same', kernel_initializer=k_initializer)(\n",
    "        klayer.UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = klayer.concatenate([conv1, up9], axis=3)\n",
    "    conv9 = klayer.Conv2D(64, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(merge9)\n",
    "    conv9 = klayer.Conv2D(32, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(conv9)\n",
    "    conv9 = klayer.Conv2D(16, 3, activation=main_activation, padding='same', kernel_initializer=k_initializer)(conv9)\n",
    "    conv10 = klayer.Conv2D(1, 1, activation=None)(conv9)\n",
    "\n",
    "    out_layer = klayer.UpSampling2D(size=(down_sampling, down_sampling))(conv10)\n",
    "\n",
    "    layers = [conv1, conv2, conv3, conv4, conv5, conv6, conv7, conv8, conv9, conv10, out_layer]\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=layers if give_intermediate else out_layer)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate), loss=create_weighted_binary_crossentropy(zero_weight=zero_weight, one_weight=1-zero_weight), metrics=[\"accuracy\"])\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    if pretrained_weights:\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def smet(learning_rate, pretrained_weights=None, input_size=(1024, 1024, 1), down_sampling=4, give_intermediate=False, main_activation=\"sigmoid\", k_initializer=\"he_normal\", zero_weight = 0.5):\n",
    "    \"\"\"Almost directly taken from https://github.com/zhixuhao/unet. Modified to fit into memory\"\"\"\n",
    "    inputs = klayer.Input(input_size)\n",
    "    # Rescale to not take too much memory\n",
    "    scaled_inputs = klayer.MaxPooling2D(pool_size=(down_sampling, down_sampling))(inputs)\n",
    "    conv3 = klayer.Conv2D(1, 1, activation=\"relu\", use_bias=True, padding='same', kernel_initializer=k_initializer)(inputs)\n",
    "    #conv3 = klayer.Conv2D(1, 1, activation=main_activation, use_bias=True, padding='same', kernel_initializer=k_initializer)(conv3)\n",
    "    out_layer = klayer.UpSampling2D(size=(down_sampling, down_sampling))(conv3)\n",
    "    layers = [conv3, out_layer]\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=layers if give_intermediate else conv3)\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate), loss=keras.losses.MSE, metrics=[metrics.binary_accuracy, mod_jaccard])\n",
    "\n",
    "    # model.summary()\n",
    "    #all_layers_output = keras.backend.function([model.layers[0].input],\n",
    "    #           [l.output for l in model.layers[1:]])\n",
    "\n",
    "    if pretrained_weights:\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model#, all_layers_output\n",
    "\n",
    "\n",
    "def DenseNet(input_shape=None, dense_blocks=3, dense_layers=-1, growth_rate=12, nb_classes=None, dropout_rate=None,\n",
    "             bottleneck=False, compression=1.0, weight_decay=1e-4, depth=40):\n",
    "    \"\"\"\n",
    "    Creating a DenseNet\n",
    "\n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images. E.g. (28,28,1) for MNIST\n",
    "        dense_blocks : amount of dense blocks that will be created (default: 3)\n",
    "        dense_layers : number of layers in each dense block. You can also use a list for numbers of layers [2,4,3]\n",
    "                       or define only 2 to add 2 layers at all dense blocks. -1 means that dense_layers will be calculated\n",
    "                       by the given depth (default: -1)\n",
    "        growth_rate  : number of filters to add per dense block (default: 12)\n",
    "        nb_classes   : number of classes\n",
    "        dropout_rate : defines the dropout rate that is accomplished after each conv layer (except the first one).\n",
    "                       In the paper the authors recommend a dropout of 0.2 (default: None)\n",
    "        bottleneck   : (True / False) if true it will be added in convolution block (default: False)\n",
    "        compression  : reduce the number of feature-maps at transition layer. In the paper the authors recomment a compression\n",
    "                       of 0.5 (default: 1.0 - will have no compression effect)\n",
    "        weight_decay : weight decay of L2 regularization on weights (default: 1e-4)\n",
    "        depth        : number or layers (default: 40)\n",
    "\n",
    "    Returns:\n",
    "        Model        : A Keras model instance\n",
    "    \"\"\"\n",
    "\n",
    "    if nb_classes == None:\n",
    "        raise Exception('Please define number of classes (e.g. num_classes=10). This is required for final softmax.')\n",
    "\n",
    "    if compression <= 0.0 or compression > 1.0:\n",
    "        raise Exception(\n",
    "            'Compression have to be a value between 0.0 and 1.0. If you set compression to 1.0 it will be turn off.')\n",
    "\n",
    "    if type(dense_layers) is list:\n",
    "        if len(dense_layers) != dense_blocks:\n",
    "            raise AssertionError('Number of dense blocks have to be same length to specified layers')\n",
    "    elif dense_layers == -1:\n",
    "        if bottleneck:\n",
    "            dense_layers = (depth - (dense_blocks + 1)) / dense_blocks // 2\n",
    "        else:\n",
    "            dense_layers = (depth - (dense_blocks + 1)) // dense_blocks\n",
    "        dense_layers = [int(dense_layers) for _ in range(dense_blocks)]\n",
    "    else:\n",
    "        dense_layers = [int(dense_layers) for _ in range(dense_blocks)]\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "    nb_channels = growth_rate * 2\n",
    "\n",
    "    print('Creating DenseNet')\n",
    "    print('#############################################')\n",
    "    print('Dense blocks: %s' % dense_blocks)\n",
    "    print('Layers per dense block: %s' % dense_layers)\n",
    "    print('#############################################')\n",
    "\n",
    "    # Initial convolution layer\n",
    "    x = Conv2D(nb_channels, (3, 3), padding='same', strides=(1, 1),\n",
    "               use_bias=False, kernel_regularizer=l2(weight_decay))(img_input)\n",
    "\n",
    "    # Building dense blocks\n",
    "    for block in range(dense_blocks):\n",
    "\n",
    "        # Add dense block\n",
    "        x, nb_channels = dense_block(x, dense_layers[block], nb_channels, growth_rate, dropout_rate, bottleneck,\n",
    "                                     weight_decay)\n",
    "\n",
    "        if block < dense_blocks - 1:  # if it's not the last dense block\n",
    "            # Add transition_block\n",
    "            x = transition_layer(x, nb_channels, dropout_rate, compression, weight_decay)\n",
    "            nb_channels = int(nb_channels * compression)\n",
    "\n",
    "    x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = Dense(nb_classes, activation='softmax', kernel_regularizer=l2(weight_decay), bias_regularizer=l2(weight_decay))(\n",
    "        x)\n",
    "\n",
    "    model_name = None\n",
    "    if growth_rate >= 36:\n",
    "        model_name = 'widedense'\n",
    "    else:\n",
    "        model_name = 'dense'\n",
    "\n",
    "    if bottleneck:\n",
    "        model_name = model_name + 'b'\n",
    "\n",
    "    if compression < 1.0:\n",
    "        model_name = model_name + 'c'\n",
    "\n",
    "    return Model(img_input, x, name=model_name), model_name\n",
    "\n",
    "\n",
    "def dense_block(x, nb_layers, nb_channels, growth_rate, dropout_rate=None, bottleneck=False, weight_decay=1e-4):\n",
    "    \"\"\"\n",
    "    Creates a dense block and concatenates inputs\n",
    "    \"\"\"\n",
    "\n",
    "    x_list = [x]\n",
    "    for i in range(nb_layers):\n",
    "        cb = convolution_block(x, growth_rate, dropout_rate, bottleneck, weight_decay)\n",
    "        x_list.append(cb)\n",
    "        x = Concatenate(axis=-1)(x_list)\n",
    "        nb_channels += growth_rate\n",
    "    return x, nb_channels\n",
    "\n",
    "\n",
    "def convolution_block(x, nb_channels, dropout_rate=None, bottleneck=False, weight_decay=1e-4):\n",
    "    \"\"\"\n",
    "    Creates a convolution block consisting of BN-ReLU-Conv.\n",
    "    Optional: bottleneck, dropout\n",
    "    \"\"\"\n",
    "\n",
    "    # Bottleneck\n",
    "    if bottleneck:\n",
    "        bottleneckWidth = 4\n",
    "        x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(nb_channels * bottleneckWidth, (1, 1), use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n",
    "        # Dropout\n",
    "        if dropout_rate:\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Standard (BN-ReLU-Conv)\n",
    "    x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(nb_channels, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n",
    "\n",
    "    # Dropout\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_layer(x, nb_channels, dropout_rate=None, compression=1.0, weight_decay=1e-4):\n",
    "    \"\"\"\n",
    "    Creates a transition layer between dense blocks as transition, which do convolution and pooling.\n",
    "    Works as downsampling.\n",
    "    \"\"\"\n",
    "\n",
    "    x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(int(nb_channels * compression), (1, 1), padding='same',\n",
    "               use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n",
    "\n",
    "    # Adding dropout\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Define data_loader\"\"\"\n",
    "class DataLoader(keras.utils.Sequence):\n",
    "    def __init__(self, filepaths, batch_size=32, dim=(1024, 1024), shuffle=True, mask_dir=\"\"):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.filepaths = filepaths\n",
    "        self.mask_dir = mask_dir\n",
    "        self.indices = np.arange((len(self.filepaths)))\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.csv = pd.read_csv(mask_csv_filename, header=None, index_col=0)\n",
    "        with open(mask_csv_filename, mode=\"r\") as f:\n",
    "            raw_rle = f.read()\n",
    "\n",
    "        self.rles = {}\n",
    "\n",
    "        for line in raw_rle.split(\"\\n\"):\n",
    "            key, rle_data = line.split(\",\")\n",
    "            rle_data = [x for x in rle_data.split() if x != \"\"]\n",
    "            self.rles[key] = rle_data\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __data_generation(self, filepaths):\n",
    "        \"\"\"Generates data containing batch_size samples\"\"\"  # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, 1), dtype=np.uint8)\n",
    "        Y = np.empty((self.batch_size, *self.dim, 1), dtype=np.bool)\n",
    "\n",
    "        # Generate data\n",
    "        for i, filepath in enumerate(filepaths):\n",
    "            # Store sample\n",
    "            X[i,], Y[i] = self.load_filepath(filepath)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def load_filepath(self, filepath):\n",
    "        a = np.asarray(Image.open(filepath[:-4]+\".png\"))\n",
    "        a = preprocess_image(a)\n",
    "        X = a[::4,::4]\n",
    "        X = (np.expand_dims(X, axis=2).astype(np.float32) + 1) / 2\n",
    "        \n",
    "        Y = np.load(os.path.join(self.mask_dir, filepath.split(os.sep)[-1])[:-4])#.T\n",
    "        #y_rle = self.rles[filepath.split(os.sep)[-1][:-4]]\n",
    "        #Y = rle2mask(y_rle, *self.dim).T\n",
    "        #  Y = np.reshape(Y, self.dim)\n",
    "        #  Y = np.expand_dims(Y, axis=2).astype(np.float)\n",
    "        #  Y = (X>0.5).astype(np.float)\n",
    "        return X, X.copy()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.filepaths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        batch_shuffled_files = [self.filepaths[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, Y = self.__data_generation(batch_shuffled_files)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "def check_valid_datafile(filepath, rle_df, needs_label=True):\n",
    "    # We try to load each file in order to find which ones are invalid\n",
    "    try:\n",
    "        xray_image = Image.open(filepath)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Skipping loading of {filepath}, file didn't load correctly\")\n",
    "        return False\n",
    "\n",
    "    if needs_label:\n",
    "        try:\n",
    "            str(rle_df.loc[filepath.split(os.sep)[-1][:-4], 1])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Skipping loading of {filepath}, file doesn't have label when it should\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def mask2rle(img, width, height):\n",
    "    rle = []\n",
    "    lastColor = 0\n",
    "    currentPixel = 0\n",
    "    runStart = -1\n",
    "    runLength = 0\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            currentColor = img[x][y]\n",
    "            if currentColor != lastColor:\n",
    "                if currentColor == 255:\n",
    "                    runStart = currentPixel\n",
    "                    runLength = 1\n",
    "                else:\n",
    "                    rle.append(str(runStart))\n",
    "                    rle.append(str(runLength))\n",
    "                    runStart = -1\n",
    "                    runLength = 0\n",
    "                    currentPixel = 0\n",
    "            elif runStart > -1:\n",
    "                runLength += 1\n",
    "            lastColor = currentColor\n",
    "            currentPixel += 1\n",
    "\n",
    "    return \" \".join(rle)\n",
    "\n",
    "\n",
    "def rle2mask(rle, width, height):\n",
    "    mask = np.zeros(width * height)\n",
    "    if rle[0] == \"-1\":\n",
    "        return mask\n",
    "    split_data = [x for x in rle if x.isdigit()]\n",
    "    array_data = [int(x) for x in split_data]\n",
    "    array = np.asarray(array_data)\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "    if len(starts) > len(lengths):\n",
    "        starts = starts[:len(lengths)]\n",
    "\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        current_position += start\n",
    "        mask[current_position:min(current_position + lengths[index], (width * height) - 1)] = 255\n",
    "        current_position += lengths[index]\n",
    "\n",
    "    return mask.reshape(width, height)\n",
    "\n",
    "\n",
    "# def show_dcm_info(dataset):\n",
    "#     print(\"Filename.........:\", file_path)\n",
    "#     print(\"Storage type.....:\", dataset.SOPClassUID)\n",
    "#     print()\n",
    "#\n",
    "#     pat_name = dataset.PatientName\n",
    "#     display_name = pat_name.family_name + \", \" + pat_name.given_name\n",
    "#     print(\"Patient's name......:\", display_name)\n",
    "#     print(\"Patient id..........:\", dataset.PatientID)\n",
    "#     print(\"Patient's Age.......:\", dataset.PatientAge)\n",
    "#     print(\"Patient's Sex.......:\", dataset.PatientSex)\n",
    "#     print(\"Modality............:\", dataset.Modality)\n",
    "#     print(\"Body Part Examined..:\", dataset.BodyPartExamined)\n",
    "#     print(\"View Position.......:\", dataset.ViewPosition)\n",
    "#\n",
    "#     if 'PixelData' in dataset:\n",
    "#         rows = int(dataset.Rows)\n",
    "#         cols = int(dataset.Columns)\n",
    "#         print(\"Image size.......: {rows:d} x {cols:d}, {size:d} bytes\".format(\n",
    "#             rows=rows, cols=cols, size=len(dataset.PixelData)))\n",
    "#         if 'PixelSpacing' in dataset:\n",
    "#             print(\"Pixel spacing....:\", dataset.PixelSpacing)\n",
    "\n",
    "def preprocess_image(image_array: np.ndarray):\n",
    "    scaled_image_array = (image_array.astype(np.float16) - 128) / 128\n",
    "    return scaled_image_array\n",
    "\n",
    "\n",
    "def preprocess_mask(mask: np.ndarray):\n",
    "    #mask = mask-128\n",
    "    #mask = mask/128\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check that all data exists and is properly preprocessed\"\"\"\n",
    "train_data_pref = data_dir + \"train_png\"\n",
    "test_data_pref = data_dir + \"test_png\"\n",
    "\n",
    "try:\n",
    "    with open(data_dir + \"valid_train_filepaths\", mode=\"r\") as f:\n",
    "        valid_train_filepaths = f.read().split(\"\\n\")\n",
    "    print(\"Loaded data from old list of valid data files\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Re-checking which data files are valid\")\n",
    "    print(os.path.join(mask_csv_filename))\n",
    "    rle_data = pd.read_csv(mask_csv_filename, header=None, index_col=0)\n",
    "    valid_train_filepaths = [file_path[:-4]+\".npy\" for file_path in\n",
    "                             glob(os.path.join(train_data_pref, \"*.png\"), recursive=True)\n",
    "                             if check_valid_datafile(file_path, rle_data)]\n",
    "    valid_test_filepaths = [file_path[:-4]+\".npy\" for file_path in\n",
    "                            glob(os.path.join(test_data_pref, \"*.png\"), recursive=True)\n",
    "                            if check_valid_datafile(file_path, rle_data, needs_label=False)]\n",
    "\n",
    "    print(len(valid_test_filepaths), len(valid_train_filepaths))\n",
    "\n",
    "    print(\"Converting all files into numpy-native format\")\n",
    "\n",
    "    def store_np_file(filepath):\n",
    "        pass#a = np.asarray(Image.open(filepath[:-4]+\".png\"))\n",
    "        #a = preprocess_image(a)\n",
    "        #a = np.expand_dims(a, axis=2)\n",
    "        #np.save(filepath, a)\n",
    "\n",
    "    import sys\n",
    "\n",
    "    for inx, f in enumerate(valid_test_filepaths):\n",
    "        store_np_file(f)\n",
    "        if inx % 100 == 0:\n",
    "            print(inx)\n",
    "    for inx, f in enumerate(valid_train_filepaths):\n",
    "        store_np_file(f)\n",
    "        if inx % 100 == 0:\n",
    "            print(inx)\n",
    "\n",
    "    with open(data_dir + \"valid_train_filepaths\", mode=\"w\") as f:\n",
    "        f.write(\"\\n\".join(valid_train_filepaths))\n",
    "    with open(data_dir + \"valid_test_filepaths\", mode=\"w\") as f:\n",
    "        f.write(\"\\n\".join(valid_test_filepaths))\n",
    "\n",
    "with open(mask_csv_filename, mode=\"r\") as f:\n",
    "    raw_rle = f.read()\n",
    "\n",
    "def check_store_mask_file(raw_csv_data):\n",
    "    key, rle_d = raw_csv_data.split(\",\")\n",
    "    try:\n",
    "        with open(os.path.join(data_dir, \"train_png\", \"masks\", key), mode=\"r\") as f:\n",
    "            pass\n",
    "    except FileNotFoundError:\n",
    "        rle_d = [x for x in rle_d.split() if x != \"\"]\n",
    "        mask = rle2mask(rle_d, 1024, 1024).astype(np.bool)\n",
    "        mask = preprocess_mask(mask)\n",
    "        mask = mask.reshape((1024, 1024)).T\n",
    "        #plt.imshow(mask)\n",
    "        #plt.show()\n",
    "        with open(os.path.join(data_dir, \"train_png\", \"masks\", key), mode=\"wb\") as f:\n",
    "            np.save(f, mask)\n",
    "\n",
    "    return os.path.join(data_dir, \"train_png\", \"masks\", key)\n",
    "\n",
    "mask_processing_pool = Pool(cpu_count())\n",
    "try:\n",
    "    with open(os.path.join(data_dir, \"valid_mask_paths\"), mode=\"r\") as f:\n",
    "        valid_mask_paths = f.read().split(\"\\n\")\n",
    "        print(\"Used precomputed valid mask paths\")\n",
    "except FileNotFoundError:\n",
    "    valid_mask_paths = []\n",
    "    print(\"Computing valid mask paths\")\n",
    "    for inx, key in enumerate(raw_rle.split(\"\\n\")):\n",
    "        valid_mask_paths.append(check_store_mask_file(key))\n",
    "        if inx % 100 == 0:\n",
    "            print(inx)\n",
    "\n",
    "    with open(os.path.join(data_dir, \"valid_mask_paths\"), mode=\"w\") as f:\n",
    "        f.write(\"\\n\".join(valid_mask_paths))\n",
    "\n",
    "    print(\"Done computing valid mask paths\")\n",
    "\n",
    "print(\"Setup done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setup network training params\"\"\"'\n",
    "\n",
    "# Network and training params/config\n",
    "dims = (256,256)\n",
    "n_epochs = 10\n",
    "batch_size = 1\n",
    "img_downsampling = 16\n",
    "learning_rate = 1e-4\n",
    "num_train_examples = 10\n",
    "use_validation = False\n",
    "validation_coeff = 0.1\n",
    "retrain = True\n",
    "net_arch = \"unet\"\n",
    "\n",
    "# The file in which trained weights are going to be stored\n",
    "net_filename = f\"{net_arch}-epochs_{n_epochs}-batchsz_{batch_size}-lr_{learning_rate}-downsampling_{img_downsampling}-numexamples_{num_train_examples}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Filter filepaths to ones that we actually want to train against\"\"\"\n",
    "with open(mask_csv_filename, mode=\"r\") as f:\n",
    "        raw_rle = f.read()\n",
    "raw_csv_data = raw_rle.split(\"\\n\")\n",
    "haspneumo_lookup = {}\n",
    "for line in raw_csv_data:\n",
    "    key,rle = line.split(\",\")\n",
    "    haspneumo_lookup[key] = False if rle.strip() == \"-1\" else True\n",
    "\n",
    "pneumo_filepaths = []\n",
    "for path in valid_train_filepaths:\n",
    "    if haspneumo_lookup[os.path.split(path)[1][:-4]]:\n",
    "        pneumo_filepaths.append(path)\n",
    "\n",
    "use_filepaths = pneumo_filepaths\n",
    "num_validation_examples = int(num_train_examples * validation_coeff)\n",
    "train_filepaths = use_filepaths[:-int(validation_coeff*len(use_filepaths)) if use_validation else len(use_filepaths)][:num_train_examples]\n",
    "validation_filepaths = use_filepaths[-int(validation_coeff*len(use_filepaths)):][:num_validation_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train the network\"\"\"\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = locals()[net_arch](down_sampling=img_downsampling, learning_rate=learning_rate)\n",
    "\n",
    "try:\n",
    "    if retrain:\n",
    "        raise Exception\n",
    "    print(\"Loading pretrained network weights, from\", os.path.join(data_dir + \"models\", net_filename))\n",
    "    model.load_weights(os.path.join(data_dir + \"models\", net_filename))\n",
    "except Exception as e:\n",
    "    print(\"Was not able to load model...\")\n",
    "    print(\"Training network!\")\n",
    "\n",
    "    train_generator = DataLoader(train_filepaths, dim=(256, 256), batch_size=batch_size,\n",
    "                                 mask_dir=os.path.join(data_dir, \"train_png\", \"masks\"))\n",
    "    if use_validation:\n",
    "        validation_generator = DataLoader(validation_filepaths, batch_size=batch_size,\n",
    "                                      mask_dir=os.path.join(data_dir, \"train_png\", \"masks\"))\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.TensorBoard(log_dir=config[\"logdir\"], histogram_freq=1, write_grads=True,\n",
    "                                                  write_graph=True, write_images=True),\n",
    "        BeholderCallback(log_dir=config[\"logdir\"]),\n",
    "        keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=4)\n",
    "    ]\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    try:\n",
    "        please_stop = False\n",
    "        model.fit_generator(train_generator, validation_data=validation_generator if use_validation else None,\n",
    "                            validation_freq=1 if use_validation else None,\n",
    "                            epochs=n_epochs, use_multiprocessing=True, callbacks=callbacks)\n",
    "    except KeyboardInterrupt:\n",
    "        please_stop = True\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    finally:\n",
    "        print(\"Saving model weights in\", os.path.join(data_dir, \"models\", net_filename))\n",
    "        model.save_weights(os.path.join(data_dir, \"models\", net_filename))\n",
    "        print(\"Done saving model!\")\n",
    "        if please_stop:\n",
    "            exit()\n",
    "train_generator = DataLoader(train_filepaths, batch_size=batch_size, mask_dir=os.path.join(data_dir, \"train_png\", \"masks\"))\n",
    "prediction_model = locals()[net_arch] \\\n",
    "    (down_sampling=img_downsampling, learning_rate=learning_rate, give_intermediate=False)\n",
    "\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prediction/visualisation config\"\"\"\n",
    "# Visualisation config\n",
    "images_per_row = 16\n",
    "layers_to_vis = []#[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "figure_suffix = \".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot network predictions\"\"\"\n",
    "\n",
    "print(\"Plotting predictions...\")\n",
    "\n",
    "import math\n",
    "def plot_hidden_layer_activations(pred, layer_inx, imgs_per_row=None, filename=\"\"):\n",
    "    if not imgs_per_row:\n",
    "        imgs_per_row = images_per_row\n",
    "    # Displays the feature maps\n",
    "    n_features = pred.shape[-1]  # Number of features in the feature map\n",
    "    size = pred.shape[0]  # The feature map has shape (1, size, size, n_features).\n",
    "    n_cols = math.ceil(n_features / imgs_per_row) # Tiles the activation channels in this matrix\n",
    "    display_grid = np.zeros((size * n_cols, imgs_per_row * size))\n",
    "    for col in range(n_cols):  # Tiles each filter into a big horizontal grid\n",
    "        for row in range(imgs_per_row):\n",
    "            try:\n",
    "                channel_image = pred[:, :, col * imgs_per_row + row]\n",
    "            except IndexError:\n",
    "                break\n",
    "            # channel_image -= channel_image.mean()  # Post-processes the feature to make it visually palatable\n",
    "            # channel_image /= channel_image.std()\n",
    "            # channel_image *= 64\n",
    "            # channel_image += 128\n",
    "            # channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size: (col + 1) * size,  # Displays the grid\n",
    "            row * size: (row + 1) * size] = channel_image\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.grid(False)\n",
    "    plt.title(\"Layer nr. \" + str(layer_inx + 1))\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='bone')\n",
    "    plt.savefig(os.path.join(data_dir, \"plots\", \"Layer_\" + str(layer_inx+1) + \"_\" + filename + figure_suffix), bbox_inches=\"tight\")\n",
    "\n",
    "for to_predict in train_filepaths:\n",
    "    print(\"Plotting predictions/layers from\", os.path.split(to_predict)[1], \"...\")\n",
    "    x, y = train_generator.load_filepath(to_predict)\n",
    "\n",
    "    pred_layers = prediction_model.predict(np.asarray([x]))\n",
    "    plt.grid(False)\n",
    "    plt.title(\"Input\")\n",
    "    plt.imshow(x.squeeze().astype(np.float32), aspect='auto', cmap='bone')\n",
    "    plt.savefig(os.path.join(data_dir, \"plots\", \"Input_\" + os.path.split(to_predict)[1] + figure_suffix), bbox_inches=\"tight\")\n",
    "    plt.close('all')\n",
    "    for layer_inx in layers_to_vis:\n",
    "        print(\"\\tOn layer nr.\", layer_inx+1)\n",
    "        pred = pred_layers[layer_inx][0]\n",
    "        plot_hidden_layer_activations(pred, layer_inx, filename=os.path.split(to_predict)[1])\n",
    "        plt.close('all')\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(pred_layers.squeeze().round(), vmin=0, vmax=1)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(x.squeeze().astype(np.float32), vmin=0, vmax=1)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(pred_layers.squeeze(), vmin=0, vmax=1)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(y.squeeze(), vmin=0, vmax=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
